---
title: 'Find Out How many Times Faster your Code is'
author: Nicholas Tierney
date: '2024-05-17'
slug: summary-benchmark
categories:
  - benchmark
  - microbenchmark
  - rstats
  - functions
  - rse
  - research software engineer
tags:
  - benchmark
  - microbenchmark
  - rstats
  - research software engineer
  - rse
output: hugodown::md_document
---

```{r setup, include = FALSE}
options(cli.width = 70)  # For tidyverse loading messages
knitr::opts_chunk$set(
  tidy.opts = list(width.cutoff = 70),  # For code
  width = 70,
  collapse = TRUE, 
  comment = "#>", 
  fig.width = 7, 
  fig.align = 'center',
  fig.asp = 0.618, # 1 / phi
  fig.retina = 2,
  out.width = "700px"
)
```

```{r}
#| echo: false
knitr::include_graphics(
  path = here::here("content/post/2024/2024-05-17-summary-benchmark/blinds.jpg")
)
```

_My venetian blinds, in black and white_

I recently watched [Josiah Parry's](https://josiahparry.com/) wonderful video, ["Making R 300x times faster!"](https://www.youtube.com/watch?v=-v9qaqaj4Ug) It's a great demonstration of how to rewrite code to be faster, and it's worth your time. He rewrites some R code to be faster, then improves the speed again by writing some Rust code, which is called from R. He gets a 300 times speedup, which is really awesome.

Then someone writes in with an example of some code that is even faster than that, just using R code. It ends up being about 6 times faster than his Rust code. So a (300x6) 2000 times speed up. The main thing that helped with that was ensuring to vectorise your R code. Essentially, not working on the rows, but instead working on the columns.

Throughout the video Josiah makes good use of the [`bench`](https://github.com/r-lib/bench) R package to evaluate how much faster your code is. This idea is called "microbenchmarking", and it involves running your code many times to evaluate how much faster it is than some other option. The reason you want to run your code many times is there is often variation around the runtimes in your code, so you don't just want to base your improvements around a single measurement. It's a general standard approach to attempt tp truly compare your approach to another. 

All this being said, you should be wary of trying to make your code fast first without good reason. You want to make sure your code does the right thing first. Don't just start trying to write performant code. Or as [Donald Knuth](https://en.wikiquote.org/wiki/Donald_Knuth) says:

> "The real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; **premature optimization is the root of all evil (or at least most of it) in programming.**".

If you want to learn more about how to speed up your code, I think it's worthwhile reading up on the [measuring performance](https://adv-r.hadley.nz/perf-measure.html) chapter in Advanced R.

# An example microbenchmark

Let's take an example from the [`naniar`](https://naniar.njtierney.com/) package. I'll give more detail of this story of this optimisation at the end of this section. For the moment, let's say we want to get the number of missing values in a row of a data frame. We can do something like this:

```{r}
library(dplyr)
my_n_miss <- function(data){
  data |> 
  rowwise() |> 
  mutate(
    n_miss = sum(is.na(c_across(everything())))
  ) |> 
    ungroup()
}

my_n_miss(airquality)
```

But we can speed this up using `rowSums()` instead:

```{r}
new_n_miss <- function(data){
  n_misses <- rowSums(is.na(data))
  data |> 
  mutate(
    n_miss = n_misses
  ) |> 
    as_tibble()
}

new_n_miss(airquality)
my_n_miss(airquality)
```

We can measure the speed using `bench::mark()`:

```{r}
library(bench)

bm <- mark(
  old = my_n_miss(airquality),
  new = new_n_miss(airquality)
)

bm
```

This runs the code at least twice, and prints out the amount of time it takes to run the code provided on the right hand side of "old" and "new". But you can name them whatever you want.

Now, it can be kind of hard to see just _how much_ faster this is, if you just look at comparing the times, as the times are given here in...well, actually I'm not sure why our friend from the greek alphabet mu, µ, from the greek alphabet is here, actually? If, like me, you needed to [double check the standard measures of order of magnitude wiki page](https://simple.wikipedia.org/wiki/Order_of_magnitude), you might not know that "ms" means milli - or one thousandth, and µ means "micro", or one millionth. The point is that the new one is many times faster than the old one.

We can do a plot to help see this:

```{r}
plot(bm)
```

So we can see that the new one really is _a lot_ faster. 

But if I just want to be able to say something like:

> It is XX times faster

then we can use the (somewhat unknown?) `relative = TRUE` option of [bench's S3 method for `summary` method](https://bench.r-lib.org/reference/summary.bench_mark.html):

```{r}
summary(bm, relative = TRUE)
```

And this is great, from this we can see it is about 60 times faster. And that the old approach uses 15 times more memory.

## The story behind this speedup in naniar.

Now, I didn't just come up with a speedup for missing values on the fly. The story here is that there was going to be some (very generous) improvements to the naniar package from [Romain François](https://github.com/romainfrancois) [in the form of C++ code](https://github.com/njtierney/naniar/issues/113). However, [Jim Hester](https://www.jimhester.com/) suggested some changes, I think twitter (which I can't find anymore), and he then kindly submitted a [pull request showing that rowSums in R ends up being plenty fast](https://github.com/njtierney/naniar/pull/112/).

This is a similar story to Josiah's, where he used Rust code to get it faster, but then there was a faster way just staying within R. 

Sometimes, you don't need extra C or Fortran or Rust. R is enough!

And if you want to be able to compare the speeds of things, don't forget the `relative = TRUE` argument in `summary` when using `bench::mark`.

# Other packages for microbenchmarking

`bench` isn't the only way to measure things! Other ones I've enjoyed using in the past are [microbenchmark](https://cran.r-project.org/web/packages/microbenchmark/index.html) and [tictoc](https://cran.r-project.org/web/packages/tictoc/index.html). I've particularly enjoyed `tictoc` because you get to do this:

```{r}
library(tictoc)
tic()
new_n_miss(airquality)
toc()
```

Which feels a bit nicer than using `system.time()`:

```{r}
system.time({
  new_n_miss(airquality)
})
```

Also, notice that those two times are different? This is why we use benchmarking, to run those checks many times!

# End

And that's it, that's the blog post. The `relative = TRUE` option in `mark` is super neat, and I don't think many people know about it. Thanks again to Jim Hester for originally creating the `bench` package.

