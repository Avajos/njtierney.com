---
title: "Smush and glue: A Pattern to Read in Excel Data with Multiple Headers"
author: Nicholas Tierney
date: '2021-08-13'
slug: read-in-excel-data-with-multiple-headers
categories:
  - rstats
  - rbloggers
tags:
  - rstats
  - data cleaning
  - dplyr
  - rbloggers
draft: yes
output: hugodown::md_document
---

```{r setup, include = FALSE}
options(cli.width = 70)  # For tidyverse loading messages
knitr::opts_chunk$set(
  tidy.opts = list(width.cutoff = 70),  # For code
  width = 70,
  collapse = TRUE, 
  comment = "#>", 
  fig.width = 7, 
  fig.align = 'center',
  fig.asp = 0.618, # 1 / phi
  fig.retina = 2,
  out.width = "700px"
)
```

```{r}
#| echo: false
library(knitr)
library(here)
library(tidyverse)
```


```{r image-banner, echo = FALSE, out.width = "100%"}
include_graphics("figs/fences.jpg")
```

<p align="right" font-size="12px"> Photo By <a href="https://www.instagram.com/">Nick Tierney</a> </p>    

I've recently had to clean up some excel data - it was really challenging as the first few rows of the spreadsheet contained data different types of data. It looked something like this example I've made up Let's consider this as an agriculture example of pesticide doses.

In excel, it looks like so:

```{r show-excel, echo = FALSE}
include_graphics("figs/ss-screenshot.png")
```

There's a lot going on here - let's unpack it:

1. We've got weekly **time** components going across in a merged column along the top.
2. Farm **site** information merged across two cells
3. **spray** one and two data under that site data
4. **count** information under these cells, representing the number of pests killed
5. We are measuring pest size, and pesticide type appropriately, I think.

Here's that information marked up:

```{r show-excel-marked-up, echo = FALSE}
include_graphics("figs/ss-screenshot-marked-up.png")
```

I was stuck! But I soon found some great help from [Alison Hill](https://alison.rbind.io/blog/2018-07-multiple-headers/), and [Lisa DeBruine](https://debruine.github.io/posts/multi-row-headers/). I also came across this [answer on a stack overflow thread](https://stackoverflow.com/a/62614924/3764040), by user [a5c1d2h2i1m1n2o1r2t1](https://stackoverflow.com/users/1270695/a5c1d2h2i1m1n2o1r2t1) (I mean, what a name). 

They all led me to solve the problem, hooray! I thought I'd add to that body of knowledge.

# How to solve this problem

Here's part of my process for data cleaning and tidying.

1. Pre visualising - what is the data I want? (identifying what are the variables, the rows, and cells)
2. Map which parts of the messy data map to the new columns that I need.

# Pre-visualising

The first step I took in solving this, and what I try and do when I get a messy dataset, is to imagine what columns I will have at the end of the cleaning.

When I'm faced with something tricky and tough like this, I try and write down the columns of data that I think I'll end up with. Often times I turn to a pen and paper to help get started. Then I might turn to some code to help formalise it. 

A big part of this process is identifying the three parts of what is known in the business as ["tidy data"](https://r4ds.had.co.nz/tidy-data.html) ([original paper](https://vita.had.co.nz/papers/tidy-data.pdf)):

1. What form the variables?
2. What form the rows?
3. What is in each cell?

Once you can identify these components, you've got some kind of bounds for your data, you know what it will look like when it's done.

That being said, sometimes this is the hardest part of data cleaning! It can take some practice to identify these things. I still regularly get stuck.

So here's my thinking - going back to that marked up figure earlier

* I have time data, week 1 and week 2
* I have some site level data, site 1 and site 2
* I have spray data - spray 1 and spray 2
* I have pest size data
* I have pesticide data
* I have counts

We can use `expand_grid` to take unique combinations of vectors and make a data frame. This means it takes all the possible combinations of the input data and puts it into a data frame. For example, if I've got numbers, 1 and 2, and letters, A, B, and C, we can do the following:

```{r}
library(tidyr)
expand_grid(num = 1:2, 
            letters = c("A", "B", "C"))
```

So now we can take what we know about each of the variables we have, and what values they will take, and will then create them with:

```{r}
mock_pest_data <- expand_grid(
  time = c(1,2),
  site = c(1,2),
  spray = c(1,2),
  pest_size = c("1-3", "4-7", "8-10"),
  pesticide_name = c("roundup", "garden_dust")
) 

mock_pest_data
```

Then we need to add some count data - we can do this like so:

```{r}
mock_pest_data %>% 
  mutate(count = sample(1:n(), size = n()))
```

If nothing else, maybe now you've got some data you can play with, share, and imagine what other things you want to start to think about.  For example, maybe you need to work out when timepoint 1 starts? What are we counting again? Is it the number of insects killed, impacted, found? How far apart are the weeks?

It helps you get started, and going through this process might feel a bit slow at first, but for tricky problems, and especially when you are first starting out, this is really nice.

## OK but how do I actually clean the spreadsheet?

Alright, alright, alright.

We'll get there soon, but in order to try and tidy this effectively we need to take a short journey into understanding a few other similar types of data cleaning problems. Once we've done that, in ways that make sense, we can start to combine them together in cool ways.

A general problem with ["data rectangling"](https://posit.co/resources/videos/data-rectangling/) (a term coined by [Jenny Bryan](https://jennybryan.org/)) is that values are stored in variable names. Say, sites are in the columns:

```{r}
set.seed(2021-08-22)
library(tidyverse)
rand_int <- function(n) sample(x = 1:100, size = n, replace = TRUE)
df_size_wide <- tibble(
  site = c("1", "2"),
  size_1_3 = rand_int(2),
  size_4_7 = rand_int(2)
)

df_size_wide
```

Here we've got two variables, site, and size, and the count of each thing - so we'd expect some data like:

```{r}
expand_grid(
  site = c("1", "2"),
  size = c("1-3", "4-7")
) %>% 
  mutate(count = 1:n())
```

We can get it into shape using `pivot_longer` like so:

```{r}
df_size_wide %>% 
  pivot_longer(
    cols = -site,
    names_to = "size",
    values_to = "count"
  )
```

This gets us nearly all the way -  we could remove the "size_" part using `str_subset` (which automatically goes to the end of the character string by default given only a starting position):

```{r}
df_size_wide %>% 
  pivot_longer(
    cols = -site,
    names_to = "size",
    values_to = "count"
  ) %>% 
  mutate(size = str_sub(size, start = 6))
```


Like I said, a general problem with data rectangling is that values are stored in variable names. However in our case:

```{r show-excel-out, ref.label='show-excel', echo = FALSE}
```


There are many layers of variable names. And we can't pivot them all if they're like that.

But I what if instead your data look like this? 

```{r}
df_site_plus_wide <- rbind(
  rep(c("time_1", "time_2"), length.out = 4),
  rand_int(4),
  rand_int(4)
) %>% 
  as.data.frame() %>% 
  setNames(rep(c("site_1", "site_2"), each = 2)) %>% 
  as_tibble(.name_repair = janitor::make_clean_names) %>% 
  mutate(size = c("-", "size_1_4", "size_5_9"), .before = site_1)


df_site_plus_wide

```

Pivotting doesn't really help - you get stuck:

```{r}
df_site_plus_wide %>% 
  pivot_longer(
    cols = -size
  )
```

We've now got these "-" rows, and that's a bit confusing.

We could try slicing this out, like so:

```{r}
df_site_plus_wide %>% 
  slice(-1) %>% 
  pivot_longer(cols = -size)
```

But in doing so, we lose the time information... So we're a bit stuck (for the moment!)

# A similar problem

Separating columns out can be really helpful - imagine instead our data looks like this:

```{r}
df_separate <- tibble(
  size = rep(c("1_4", "5_9"), each = 4),
  site_time = c(
    "site_1-time_1",
    "site_1-time_1",
    "site_1-time_2",
    "site_1-time_2",
    "site_2-time_1",
    "site_2-time_1",
    "site_2-time_2",
    "site_2-time_2"
  ),
  count = 1:8
)

df_separate
```

We can separate out the columns using `separate`, like so:

```{r}
df_separate %>%
  separate(col = site_time,
           into = c("site", "time"),
           sep = "-")
```

And here is the secret step - can we get our data into that kind of format?

That is, like the wider version of this data:

```{r}
df_separate %>% 
  rownames_to_column() %>% 
  pivot_wider(names_from = site_time,
              values_from = count)
```


```{r}
library(vctrs)
library(glue)
df_site_plus_wide

vec_sites <- names(df_site_plus_wide) %>% 
  vec_slice(-1) %>% 
  str_sub(end = 6)
vec_sites

vec_times <- df_site_plus_wide %>% 
  slice(1) %>% 
  flatten_chr() %>% 
  vec_slice(-1)
vec_times

df_site_plus_wide %>% 
  set_names(c("size", glue("{vec_sites}__{vec_times}"))) %>% 
  slice(-1) %>% 
  pivot_longer(cols = -size) %>% 
  separate(col = name, 
           into = c("site", "time"),
           sep = "__")
  
```

# Can we combine our header and separate them?

And here is the pattern that I came across:

1. Create new smushed names that represent the header rows
2. Pivot longer
3. Separate smushed names
4. Pivot again if necessary

# Let's read in the real excel data

OK, so now we kind of have this pattern for cleaning up this kind of data.

Let's read in the excel data and see what we've got:

```{r}
library(readxl)
pest_data_excel <- read_excel(
  path = here("content/post/drafts/2021-08-13-reading-in-excel-data-with-multiple-headers/data/messy-pest-data.xlsx"),
  sheet = 1,
  skip = 1,
  .name_repair = janitor::make_clean_names,
  col_types = "text"
  )

pest_data_excel
```

Oh god.

Why are those numbers, when they should be values like "1-3" and "4-7".

This is the dreaded "excel conversion into dates" situation.

It has turned the numbers "1-3" and "4-7" into (USA type) dates. So "1-3" becomes "2021-01-03", and "4-7" becomes "2021-04-07".

Then it's turned those dates into numbers.

Confusingly, this has also left the other text values in tact.

Far out. 

Ok.

## Unexpected side quest journey time

Let's drop the first two rows:

```{r}
pest_data_excel %>% 
  slice(-c(1,2))
```

Then let's convert week into a number. date, after converting the character to number

```{r}
pest_data_excel %>% 
  slice(-c(1,2)) %>% 
  mutate(week_num = parse_number(week))
```

Then let's convert that numeric to date with `janitor`s `excel_numeric_to_date`:

```{r}
library(lubridate)
pest_data_excel %>% 
  slice(-c(1,2)) %>% 
  mutate(
    week_num = parse_number(week),
    week_new = janitor::excel_numeric_to_date(week_num),
    .after = week
    )
```

Then let's get the upper and lower values from the date of the month (`mday`) and month number `month`:

```{r}
library(lubridate)
pest_data_excel %>% 
  slice(-c(1,2)) %>% 
  mutate(
    week_num = parse_number(week),
    week_new = janitor::excel_numeric_to_date(week_num),
    lower = mday(week_new),
    upper = month(week_new),
    .after = week
    )

```

Then let's create the size column:

```{r}
library(lubridate)
pest_data_excel %>% 
  slice(-c(1,2)) %>% 
  mutate(
     week_num = parse_number(week),
    week_new = janitor::excel_numeric_to_date(week_num),
    week_new = janitor::excel_numeric_to_date(parse_number(week)),
         lower = mday(week_new),
         upper = month(week_new),
         size = glue("{lower}_{upper}")) %>% 
  select(-week_new, 
         -week, 
         -lower, 
         -upper) %>% 
  relocate(size, .after = x)
```

```{r}
library(lubridate)
pest_data_excel %>% 
  slice(-c(1,2)) %>% 
  mutate(week_new = janitor::excel_numeric_to_date(parse_number(week)),
         lower = mday(week_new),
         upper = month(week_new),
         size = glue("{lower}_{upper}")) %>% 
  select(-week_new, 
         -week, 
         -lower, 
         -upper) %>% 
  relocate(size, .after = x)
```

Yeesh this is worse than I thought.

OK, first steps - let's fix up the 

```{r}
pest_data_excel
```


# Thanks!

# Your solution?

This is just one way to clean up this kind of data - how would you do this? There's many other ways to clean this type of data! You can download the example excel data that I created for this [here]().

